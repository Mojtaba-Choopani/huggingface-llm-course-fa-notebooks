{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FcJdHNwayLv"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 30px;\">پشت پرده پایپ‌لاین در ترنسفورمرها</b>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FD8rdhaayLy"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<p>\n",
        "در فصل اول با تابع <code>pipeline()</code> آشنا شدیم.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3Ar4IgYayLz"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s808je6wayLz",
        "outputId": "011e3da7-407f-4e83-a9b3-8e6d843dbdde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<p>\n",
        "این پایپ‌لاین سه مرحله را در کنار هم قرار می‌دهد: پیش‌پردازش، عبور دادن ورودی‌ها از درون مدل، و پس‌پردازش.\n",
        "</p>\n",
        "\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> پیش‌پردازش با توکنایزر</b>\n",
        "\n",
        "<p>\n",
        "مدل‌های ترنسفورمر نمی‌توانند متن خام را مستقیماً پردازش کنند، بنابراین ابتدا باید متن را به عدد تبدیل کنیم. این کار با <b>توکنایزر</b> انجام می‌شود که وظیفه‌اش:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "  <li>شکستن متن به توکن‌ها (کلمات، زیرکلمات یا نمادها)</li>\n",
        "  <li>تبدیل هر توکن به عدد</li>\n",
        "  <li>افزودن ورودی‌های اضافی لازم برای مدل</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "تمام این مراحل باید دقیقاً مطابق با آموزش اولیهٔ مدل انجام شود. برای همین، با استفاده از کلاس <code>AutoTokenizer</code> و متد <code>from_pretrained()</code>، توکنایزر مناسب مدل را از Model Hub بارگذاری می‌کنیم.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "برای مدل پیش‌فرض تحلیل احساسات (<code>distilbert-base-uncased-finetuned-sst-2-english</code>)، این کد اجرا می‌شود.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "muoWc7gDgV68"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk3UUrbIayL0"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> تبدیل ورودی به تنسور</b>\n",
        "\n",
        "<p>\n",
        "پس از گرفتن توکنایزر، می‌توانیم جمله‌ها را به آن بدهیم و یک خروجی آماده برای مدل دریافت کنیم. تنها کار باقی‌مانده این است که شناسه‌های ورودی (<code>input IDs</code>) را به <b>تنسور</b> تبدیل کنیم.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        " <b>مدل‌های ترنسفورمر فقط تنسورها را به‌عنوان ورودی می‌پذیرند</b>، اما نگران فریم‌ورک (مثل PyTorch یا Flax) نباشید — کتابخانه  Transformers خودش آن را مدیریت می‌کند.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "اگر با تنسورها آشنایی ندارید، آن‌ها را مثل آرایه‌های NumPy تصور کنید:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "  <li>عدد (۰D)</li>\n",
        "  <li>بردار (۱D)</li>\n",
        "  <li>ماتریس (۲D) یا بیشتر</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "برای تعیین نوع تنسور، از آرگومان <code>return_tensors</code> استفاده می‌کنیم (مثلاً <code>\"pt\"</code> برای PyTorch).\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "c27lgfUuhdtp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ahgCagEayL1",
        "outputId": "0e506136-c8cb-462e-e2e7-66561462f36f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\n",
              "    'input_ids': tensor([\n",
              "        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],\n",
              "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
              "    ]), \n",
              "    'attention_mask': tensor([\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "    ])\n",
              "}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S05wAveqayL1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4USWDOsGayL1",
        "outputId": "dde1a782-2a09-4af0-bd67-5f07f2fa281e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 16, 768])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AibBKHJQayL2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAhOguq2ayL2",
        "outputId": "52b27761-3fac-4419-8a97-017b585fdd77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC_bZSj2ayL2",
        "outputId": "ab4d6b56-b02e-473e-f295-344daa2f6d27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.5607,  1.6123],\n",
              "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qULfZMV0ayL2",
        "outputId": "f92b149f-9444-47c7-db1e-4718a5811690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4.0195e-02, 9.5980e-01],\n",
              "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YziKJnUMayL3",
        "outputId": "fec132cb-77e9-4253-d3a6-414c60e5138e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.id2label"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Behind the pipeline (PyTorch)",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}