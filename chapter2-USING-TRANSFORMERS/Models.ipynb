{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mojtaba-Choopani/huggingface-llm-course-fa-notebooks/blob/main/chapter2-USING-TRANSFORMERS/Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acec2dBNUNQF"
      },
      "source": [
        "# Models (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40yEzZVpUNQJ"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> Ø³Ø§Ø®Øª ØªØ±Ù†Ø³ÙÙˆØ±Ù…Ø±</b>\n",
        "\n",
        "<p>\n",
        "Ù…ØªØ¯ <code>from_pretrained()</code> Ù…Ø¯Ù„ Ø±Ø§ Ø§Ø² <b>Hugging Face Hub</b> Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ú©Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù†Ø§Ù… <b>Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª</b> Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡Ù” Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ Ø§Ø³ØªØ› Ù…Ø«Ù„Ø§Ù‹ ÛŒÚ© Ù…Ø¯Ù„ BERT Ø¨Ø§ Û±Û² Ù„Ø§ÛŒÙ‡ØŒ Ø§Ù†Ø¯Ø§Ø²Ù‡Ù” Ù¾Ù†Ù‡Ø§Ù† Û·Û¶Û¸ Ùˆ Û±Û² Ø³Ø± ØªÙˆØ¬Ù‡ØŒ Ú©Ù‡ Ø¨Ù‡ Ø¨Ø²Ø±Ú¯ÛŒ Ùˆ Ú©ÙˆÚ†Ú©ÛŒ Ø­Ø±ÙˆÙ Ø­Ø³Ø§Ø³ Ø§Ø³Øª.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "Ú©Ù„Ø§Ø³ <code>AutoModel</code> ÛŒÚ© <b>Ø±ÙÙ¾ÙØ± Ø®ÙˆØ¯Ú©Ø§Ø±</b> Ø§Ø³Øª Ú©Ù‡ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù…Ø¯Ù„ Ø±Ø§ Ø§Ø² Ø±ÙˆÛŒ Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¢Ù† Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§Ú¯Ø± Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ù…ÛŒâ€ŒØ¯Ø§Ù†ÛŒØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² Ù‡Ù…Ø§Ù† Ú©Ù„Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\n",
        "</p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "1tG3EjqPVoec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ</b>\n",
        "\n",
        "<p>\n",
        "Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„ØŒ Ø§Ø² Ù…ØªØ¯ <code>save_pretrained()</code> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ <b>Ø¯Ùˆ ÙØ§ÛŒÙ„</b> Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "  <li><code>config.json</code> â†’ Ø´Ø§Ù…Ù„ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú†Ú©â€ŒÙ¾ÙˆÛŒÙ†Øª</li>\n",
        "  <li><code>pytorch_model.bin</code> â†’ Ø´Ø§Ù…Ù„ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ (state dict)</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "Ø§ÛŒÙ† Ø¯Ùˆ ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ <b>Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ù…Ø¯Ù„</b> Ú©Ø§ÙÛŒ Ù‡Ø³ØªÙ†Ø¯.\n",
        "</p>\n",
        "\n",
        "</div>\n",
        "---"
      ],
      "metadata": {
        "id": "svNHAvMuV8-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\">  Ø§Ù†Ú©ÙˆØ¯Ø± Ù…ØªÙ†</b>\n",
        "\n",
        "<p>\n",
        "Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ±Ù†Ø³ÙÙˆØ±Ù…Ø± Ø¨Ø§ <b>ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø§Ø¹Ø¯Ø§Ø¯</b>ØŒ Ø¢Ù† Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "M5SF54FZXiJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQMhN_LzXu6N",
        "outputId": "79f5b051-7773-4fef-8355-4f5263ed6ece"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<p>\n",
        "Ù…Ø§ ÛŒÚ© <b>Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ</b> Ø¨Ø§ ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "  <li><code>input_ids</code>: Ù†Ù…Ø§ÛŒØ´ Ø¹Ø¯Ø¯ÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§</li>\n",
        "  <li><code>token_type_ids</code>: Ø¨Ù‡ Ù…Ø¯Ù„ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Ú©Ø¯Ø§Ù… Ø¨Ø®Ø´ Ø§Ø² ÙˆØ±ÙˆØ¯ÛŒ Ø¬Ù…Ù„Ù‡ A Ùˆ Ú©Ø¯Ø§Ù… Ø¨Ø®Ø´ Ø¬Ù…Ù„Ù‡ B Ø§Ø³Øª (Ø¯Ø± Ø¨Ø®Ø´ Ø¨Ø¹Ø¯ÛŒ Ø¨ÛŒØ´ØªØ± ØªÙˆØ¶ÛŒØ­ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)</li>\n",
        "  <li><code>attention_mask</code>: Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ø¯Ø§Ù… ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ù…ÙˆØ±Ø¯ ØªÙˆØ¬Ù‡ Ù‚Ø±Ø§Ø± Ú¯ÛŒØ±Ù†Ø¯ Ùˆ Ú©Ø¯Ø§Ù… Ù†Ù‡ </li>\n",
        "</ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "SFV7eJ_TYF7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> Ù¾Ø¯ÛŒÙ†Ú¯ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§</b>\n",
        "\n",
        "<p>\n",
        "Ø§Ú¯Ø± Ø§Ø² ØªÙˆÚ©Ù†Ø§ÛŒØ²Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ú©Ù‡ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ <b>Ù¾Ø¯Ú¯Ø°Ø§Ø±ÛŒ</b> Ú©Ù†Ø¯ØŒ Ø¢Ù† ØªÙ…Ø§Ù… Ø¬Ù…Ù„Ø§Øª Ø±Ø§ Ø¨Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒÚ© <b>ØªÙˆÚ©Ù† ÙˆÛŒÚ˜Ù‡Ù” Ù¾Ø¯ (padding token)</b> Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ Ø¬Ù…Ù„Ø§Øª Ú©ÙˆØªØ§Ù‡â€ŒØªØ±ØŒ Ø¨Ù‡ ÛŒÚ© Ø·ÙˆÙ„ ÛŒÚ©Ø³Ø§Ù† Ù…ÛŒâ€ŒØ±Ø³Ø§Ù†Ø¯.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "nnMFxdA5ZMDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\n",
        "    [\"How are you?\", \"I'm fine, thank you!\"], padding=True, return_tensors=\"pt\"\n",
        ")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrYiumKXZRrH",
        "outputId": "2ff630ac-48c0-4af1-e867-8d82901585da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  136,  102,    0,    0,    0,    0],\n",
            "        [ 101,  146,  112,  182, 2503,  117, 6243, 1128,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> Ú©ÙˆØªØ§Ù‡â€ŒØ³Ø§Ø²ÛŒ (Truncating) ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§</b>\n",
        "\n",
        "<p>\n",
        "Ø§Ú¯Ø± Ø·ÙˆÙ„ ÙˆØ±ÙˆØ¯ÛŒ Ø§Ø² Ø­Ø¯ Ù…Ø¬Ø§Ø² Ù…Ø¯Ù„ (Ù…Ø«Ù„Ø§Ù‹ <b>ÛµÛ±Û² ØªÙˆÚ©Ù†</b> Ø¯Ø± BERT) Ø¨ÛŒØ´ØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ± <code>truncation</code> Ø¢Ù† Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ú©Ù†ÛŒÙ… ØªØ§ Ù…Ø¯Ù„ Ø¨ØªÙˆØ§Ù†Ø¯ Ø¢Ù† Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†Ø¯.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "utai13TJbjNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\n",
        "    \"This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long sentence.\",\n",
        "    truncation=True,\n",
        ")\n",
        "print(encoded_input[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1TKdq8vbpRa",
        "outputId": "c4f5c1b4-b943-4856-aef8-1ba780f31ebb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1188, 1110, 170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1263, 5650, 119, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<p>\n",
        "Ø¨Ø§ <b>ØªØ±Ú©ÛŒØ¨ Ø¯Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ±</b> <code>padding</code> Ùˆ <code>truncation</code>ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ <b>ØªÙ†Ø³ÙˆØ±Ù‡Ø§ÛŒ Ø´Ù…Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡Ù” Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²ØªØ§Ù†</b> Ù‡Ø³ØªÙ†Ø¯.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "GxjbZI04b6Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\n",
        "    [\"How are you?\", \"I'm fine, thank you!\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=5,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w5PNXcTb-im",
        "outputId": "2f884b50-8a28-4630-f4ef-e314f28b95ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1731, 1132, 1128,  102],\n",
            "        [ 101,  146,  112,  182,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\">ğŸ”– Ø§ÙØ²ÙˆØ¯Ù† ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ù‡</b>\n",
        "\n",
        "<p>\n",
        "ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ù‡ Ù…Ø§Ù†Ù†Ø¯ <code>[CLS]</code> Ùˆ <code>[SEP]</code> Ø¨Ø±Ø§ÛŒ <b>Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù† Ù…Ø±Ø² Ø¬Ù…Ù„Ù‡</b> Ùˆ <b>Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ù…Ù„Ø§Øª</b> Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ <b>BERT</b> Ø¶Ø±ÙˆØ±ÛŒ Ù‡Ø³ØªÙ†Ø¯.\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "XwnvNivpcVWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\"How are you?\")\n",
        "print(encoded_input[\"input_ids\"])\n",
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "8xcS_5emcYZv",
        "outputId": "094625b0-d877-4a4f-84da-e896d6816be3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1731, 1132, 1128, 136, 102]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] How are you? [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4B2gh-1UNQK"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JSkHNyXUNQL"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "# Building the config\n",
        "config = BertConfig()\n",
        "\n",
        "# Building the model from the config\n",
        "model = BertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcjtiiPzUNQN",
        "outputId": "7f6308d1-d393-4154-853d-bace892c7b22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  [...]\n",
              "  \"hidden_size\": 768,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  [...]\n",
              "}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjETgO_mUNQO"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "config = BertConfig()\n",
        "model = BertModel(config)\n",
        "\n",
        "# Model is randomly initialized!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1J__8SFUNQP"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h36BIB2nUNQS"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"directory_on_my_computer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvfiXMJnUNQT"
      },
      "outputs": [],
      "source": [
        "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaVJnKAjUNQU"
      },
      "outputs": [],
      "source": [
        "encoded_sequences = [\n",
        "    [101, 7592, 999, 102],\n",
        "    [101, 4658, 1012, 102],\n",
        "    [101, 3835, 999, 102],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_0pbjoIUNQV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "model_inputs = torch.tensor(encoded_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw3dW3WJUNQV"
      },
      "outputs": [],
      "source": [
        "output = model(model_inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Models (PyTorch)",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}