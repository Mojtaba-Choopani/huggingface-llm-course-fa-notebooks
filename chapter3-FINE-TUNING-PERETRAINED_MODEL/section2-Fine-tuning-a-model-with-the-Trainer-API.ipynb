{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mojtaba-Choopani/huggingface-llm-course-fa-notebooks/blob/main/chapter3-FINE-TUNING-PERETRAINED_MODEL/section2-Fine-tuning-a-model-with-the-Trainer-API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TZbKROGjGJY"
      },
      "source": [
        "# Fine-tuning a model with the Trainer API\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    کتابخانه <strong>Transformers</strong> کلاس <code>Trainer</code> را برای کمک به <strong>fine-tune</strong> مدل‌های پیش‌آموزش‌دیده فراهم می‌کند. پس از انجام تمام مراحل پیش‌پردازش داده‌ها، تنها چند مرحله باقی مانده برای تعریف <code>Trainer</code>.\n",
        "  </p>\n",
        "  <p>\n",
        "    یکی از چالش‌ها سرعت کند اجرای <code>Trainer.train()</code> در <strong>CPU</strong> است که بهتر است از <strong>GPU</strong> استفاده شود.\n",
        "  </p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQjfDtl3jGJb"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    کد زیر در بخش قبلی اجرایی و توضیح داده شد:\n",
        "  </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "RbVVsriQkwlv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoylQ2ADjGJc"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
        "\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    <strong>آموزش</strong>\n",
        "  </p>\n",
        "  <p>\n",
        "    برای شروع آموزش، ابتدا باید کلاس <code>TrainingArguments</code> را تعریف کنید که هایپرپارامترهای مورد نیاز برای آموزش و ارزیابی را شامل می‌شود. تنها آرگومانی که باید مشخص کنید، دایرکتوری ذخیره مدل و چک‌پوینت‌ها است، و برای باقی موارد می‌توانید از مقادیر پیش‌فرض استفاده کنید.\n",
        "  </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Ze9_nbe7k3fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8-ZhyCSJjGJd"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    مرحله دوم، تعریف مدل است. مانند فصل قبلی، از کلاس <strong>AutoModelForSequenceClassification</strong> استفاده خواهیم کرد، با دو برچسب:\n",
        "  </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "kLQIz2uEk9lb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z6lTlZRjGJe"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    پس از ساخت مدل پیش‌آموزش‌دیده، هشدارهایی دریافت می‌شود زیرا هد مدل برای طبقه‌بندی جفت جملات تغییر کرده است. سپس، مدل، هایپرپارامترها، مجموعه داده‌ها، <code>data_collator</code> و <code>processing_class</code> را به <code>Trainer</code> می‌دهیم. پارامتر <code>processing_class</code> به <code>Trainer</code> می‌گوید از کدام توکنایزر برای پردازش داده‌ها استفاده کند.\n",
        "  </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "VuPbd3DtnGdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jA2UHgssjGJe"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    زمانی که توکنایزر را به‌عنوان <code>processing_class</code> به <code>Trainer</code> بدهید، <code>DataCollatorWithPadding</code> به‌طور پیش‌فرض به‌عنوان <code>data_collator</code> استفاده می‌شود. در این صورت، می‌توانید خط مربوط به <code>data_collator</code> را حذف کنید.\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5GpEIuyVnq4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    برای <strong>fine-tune</strong> کردن مدل روی مجموعه داده خود، کافی است که متد <code>train()</code> را از <code>Trainer</code> فراخوانی کنیم:\n",
        "  </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "k_yvC-tIqmF4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt3Rlo3JjGJf"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    <strong>ارزیابی</strong>\n",
        "  </p>\n",
        "  <p>\n",
        "    برای ارزیابی مدل، باید تابع <code>compute_metrics()</code> را تعریف کنیم که یک شیء <code>EvalPrediction</code> می‌گیرد (یک تاپل نام‌دار با فیلدهای <code>predictions</code> و <code>label_ids</code> است) و یک دیکشنری از معیارهای ارزیابی را به‌عنوان خروجی برمی‌گرداند.\n",
        "  </p>\n",
        "  <p>\n",
        "    برای دریافت پیش‌بینی‌ها از مدل، از دستور <code>Trainer.predict()</code> استفاده می‌کنیم.\n",
        "  </p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "X2LEXtn_UtpL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gicqzZZgjGJf",
        "outputId": "fd1a1272-0b62-4e6a-b726-662f0502ade9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(408, 2) (408,)\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    خروجی متد <code>predict()</code> یک تاپل نام‌دار با سه فیلد است:\n",
        "  </p>\n",
        "  <ul>\n",
        "    <li><strong>predictions:</strong> پیش‌بینی‌های مدل به صورت آرایه‌ای دو بعدی.</li>\n",
        "    <li><strong>label_ids:</strong> شناسه‌های برچسب‌های واقعی.</li>\n",
        "    <li><strong>metrics:</strong> معیارهای ارزیابی مانند خطا و زمان پیش‌بینی.</li>\n",
        "  </ul>\n",
        "  <p>\n",
        "    برای تبدیل پیش‌بینی‌ها به نتایج نهایی، باید بیشترین مقدار از هر ردیف آرایه <code>predictions</code> را انتخاب کرد که نمایانگر کلاس پیش‌بینی‌شده است. اگر تابع <code>compute_metrics()</code> تعریف شود، معیارهای اضافی مانند دقت یا F1 نیز محاسبه می‌شوند و به فیلد <code>metrics</code> اضافه می‌شوند.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "CxseleqUvy-X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrj7zGnkjGJg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  <p>\n",
        "    برای مقایسه <code>predictions</code> با <code>labels</code> و ساخت تابع <code>compute_metrics()</code>، از معیارهای کتابخانه هاگینگ فیس <strong>Evaluate</strong> استفاده می‌کنیم. با استفاده از تابع <code>evaluate.load()</code> می‌توانیم معیارهای مربوط به مجموعه داده MRPC را بارگذاری کرده و از متد <code>compute()</code> برای محاسبه معیارها استفاده کنیم.\n",
        "  </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Xta1yjDbxX5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-6UiiVjjGJg"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQtSoPo9jGJh"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLWwa0_TjGJh"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1GAJPRSjGJh"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Fine-tuning a model with the Trainer API or Keras",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}