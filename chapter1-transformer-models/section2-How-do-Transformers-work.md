# ูุฏูโูุง ุชุฑูุณููุฑูุฑ ฺฺฏููู ฺฉุงุฑ ูโฺฉููุฏุ

ุฏุฑ ุงู ุจุฎุด ุจู ุจุฑุฑุณ ูุนูุงุฑ ูุฏูโูุง ุชุฑูุณููุฑูุฑุ ููุงูู ฺฉูุฏ ูุงููุฏ **ูุงูโูุง ุชูุฌู (attention)**ุ **ุณุงุฎุชุงุฑ EncoderโDecoder**ุ **ุงุฏฺฏุฑ ุงูุชูุงู (transfer learning)** ู ุฑููุฏ ุขููุฒุด ุขูโูุง ูโูพุฑุฏุงุฒู.  
ุงู ูุญุชูุง ุชุฑุฌูู ู ุฎูุงุตูโุง ุฏูู ุงุฒ ุฏูุฑู ุฑุณู Hugging Face ุงุณุช.

>  ุงู ุจุฎุด ูุณุจุช ุจู ุจุฎุดโูุง ูุจู ููโุชุฑ ุงุณุช. ุงฺฏุฑ ููู ฺุฒ ุฑุง ุงุฒ ุงุจุชุฏุง ูุชูุฌู ูุดุฏุฏ ูฺฏุฑุงู ูุจุงุดุฏุ ุฏุฑ ุงุฏุงููโ ุฏูุฑู ุจู ุงู ููุงูู ุจุงุฒ ุฎูุงูู ฺฏุดุช.

---

##  ุชุงุฑุฎฺู ูุฎุชุตุฑ ุชุฑูุณููุฑูุฑูุง

ูุนูุงุฑ Transformer ุฏุฑ ฺูุฆู ฒฐฑท ุจุฑุง ุชุฑุฌูู ูุนุฑู ุดุฏ. ูุฏูโูุง ููู ุฏุฑ ุงู ุญูุฒู ุจู ุชุฑุชุจ ุนุจุงุฑุชโุงูุฏ ุงุฒ:

- **2018 โ GPT**: ุงููู ูุฏู ูพุดโุขููุฒุดโุฏุฏูโ ุฎูุฏุฑฺฏุฑุณู
- **2018 โ BERT**: ุจุฑุง ุฏุฑฺฉ ุจูุชุฑ ุณุงุฎุชุงุฑ ุฌููุงุช
- **2019 โ GPT-2**: ูุณุฎู ููโุชุฑ ู ุจุฒุฑฺฏโุชุฑ GPT
- **2019 โ T5**: ุจุฑุง ูุธุงู ูุฎุชูู ุจุง ูุนูุงุฑ EncoderโDecoder
- **2020 โ GPT-3**: ุนููฺฉุฑุฏ ุนุงู ุจุฏูู ูุงุฒ ุจู fine-tuning (zero-shot)
- **2022 โ InstructGPT**
- **2023 โ LLaMA**
- **2023 โ Mistral**: ุณุฑุนโุชุฑ ู ุจูุชุฑ ุงุฒ LLaMA-2 ุจุง ทB ูพุงุฑุงูุชุฑ
- **2024 โ Gemma 2**: ุณุจฺฉ ู ูุงุจู ุฑูุงุจุช ุจุง ูุฏูโูุง ุจุฒุฑฺฏโุชุฑ
- **2024 โ SmolLM2**: ูุฏู ฺฉูฺฺฉ ุจุง ุนููฺฉุฑุฏ ฺุดูโฺฏุฑ ุฑู ุฏุณุชฺฏุงูโูุง ฺฉูโููุจุน

### ุฏุณุชูโุจูุฏ ุงุตู ูุฏูโูุง:
- **GPT-like**: ุฎูุฏุฑฺฏุฑุณู (Auto-regressive)
- **BERT-like**: ุฎูุฏุฑูุฒฺฏุฐุงุฑ (Autoencoding)
- **T5-like**: ุงูฺฉูุฏุฑโุฏฺฉูุฏุฑ (Sequence-to-sequence)

---

##  ุชุฑูุณููุฑูุฑูุง ูุฏูโูุง ุฒุจุงู ูุณุชูุฏ

ุชูุงู ุงู ูุฏูโูุง ุจู ุนููุงู **Language Model** ุขููุฒุด ุฏุฏูโุงูุฏ. ุนู ุจุง ุญุฌู ุฒุงุฏ ุงุฒ ูุชู ุฎุงู ู ุจู ุตูุฑุช **ุฎูุฏูุธุงุฑุช (self-supervised)** ุขููุฒุด ุฏุฏูโุงูุฏ.

###  ุขููุฒุด ูุฏู ุฒุจุงู ุดุงูู ุฏู ููุน ุงุณุช:

- **Causal Language Modeling**: ูพุดโุจู ูุงฺูโ ุจุนุฏ ุจุง ุชูุฌู ุจู ูุงฺูโูุง ูุจู  
- **Masked Language Modeling**: ูพุดโุจู ูุงฺูโ ุญุฐูโุดุฏู (ูุงุณฺฉโุดุฏู) ุฏุฑ ุฌููู

###  ุณูพุณ ูุฏู ูุงุฑุฏ ูุฑุญููโ ุชูุธู ูุฌุฏุฏ (Fine-tuning) ูโุดูุฏ:
- ุจุง ุฏุงุฏูโูุง ุจุฑฺุณุจโุฏุงุฑ ุฑู ฺฉ ูุธูู ุฎุงุต ุขููุฒุด ูโุจูุฏ.
- ุจุงุนุซ ุตุฑููโุฌู ุฏุฑ ุฒูุงูุ ุฏุงุฏูุ ููุงุจุน ู ูุฒูู ูโุดูุฏ.
- ุฏุงูุด ุขููุฎุชูโุดุฏู ุงุฒ ูพุดโุขููุฒุด ุจู ูุฏู ููุชูู ูโุดูุฏ (Transfer Learning).

---

##  ูุฏูโูุง ุชุฑูุณููุฑูุฑ ุจุฒุฑฺฏ ู ูพุฑูุฒููโุงูุฏ

ุงฺฉุซุฑ ูุฏูโูุง ูููู ุงุฒ ููุงุฑุฏูุง ูพุงุฑุงูุชุฑ ุชุดฺฉู ุดุฏูโุงูุฏ ู ุขููุฒุด ุขูโูุง ูุงุฒ ุจู ููุงุจุน ุฒุงุฏ ูุญุงุณุจุงุช ุฏุงุฑุฏ ฺฉู ููุฌุฑ ุจู:

- ูุตุฑู ุงูุฑฺ ุจุงูุง
- ูุฒูู ูุงู ุฒุงุฏ
- ุงุซุฑุงุช ุฒุณุชโูุญุท ูุงุจู ุชูุฌู

###  ุฑุงูโุญู:
**ุงุณุชูุงุฏู ูุฌุฏุฏ ุงุฒ ูุฒูโูุง ุขููุฒุดโุฏุฏู ู ุงุดุชุฑุงฺฉโฺฏุฐุงุฑ ูุฏูโูุง** ุจุงุนุซ ฺฉุงูุด ูุฒูู ู ุฑุฏูพุง ฺฉุฑุจู ูโุดูุฏ.

### ๐ง ุงุจุฒุงุฑูุง ุชุฎูู ุงุซุฑ ุฒุณุชโูุญุท:
- [ML CO2 Impact](https://mlco2.github.io/impact)
- [CodeCarbon](https://codecarbon.io) (ุฏุฑ Transformers ๐ค)

---

##  ูุนูุงุฑ ฺฉู ูุฏู ุชุฑูุณููุฑูุฑ

ูุฏู ุชุฑูุณููุฑูุฑ ุงุฒ ุฏู ุจุฎุด ุงุตู ุชุดฺฉู ุดุฏู ุงุณุช:

- **Encoder**: ุฏุฑุงูุช ูุฑูุฏ ู ุณุงุฎุช ููุงุด ุจุฑุฏุงุฑ ุงุฒ ุขู (ุฏุฑฺฉ ูุนูุง)
- **Decoder**: ุชููุฏ ุฎุฑูุฌ ุฏูุจุงููโุง ุจุง ุชูุฌู ุจู Encoder ู ูุถุนุช ูุจู

###  ฺฉุงุฑุจุฑุฏูุง:

| ููุน ูุนูุงุฑ       | ฺฉุงุฑุจุฑุฏูุง |
|------------------|----------|
| ููุท Encoder       | ุทุจููโุจูุฏ ูุชูุ ุชุดุฎุต ููุฌูุฏุช (NER) |
| ููุท Decoder       | ุชููุฏ ูุชูุ ุชฺฉูู ุฌููู |
| EncoderโDecoder  | ุชุฑุฌููุ ุฎูุงุตูโุณุงุฒุ ูพุฑุณุดโูพุงุณุฎ |

---

##  ูุงูโูุง Attention ฺุณุชูุฏุ

**ูฺฉุงูุฒู ุชูุฌู (Attention)** ุจู ูุฏู ฺฉูฺฉ ูโฺฉูุฏ ุชุดุฎุต ุฏูุฏ ููฺฏุงู ุจุฑุฑุณ ฺฉ ูุงฺูุ ุจุงุฏ ุจู ฺฉุฏุงู ูุงฺูโูุง ุฏฺฏุฑ ุฏุฑ ุฌููู ุชูุฌู ุจุดุชุฑ ฺฉูุฏ.

### ูุซุงู:
ุฏุฑ ุฌูููโ ยซYou like this courseยป  
ุจุฑุง ุชุฑุฌููโ ุฏุฑุณุช ูุงฺูโ "like"ุ ูุฏู ุจุงุฏ ุจู "You" ุชูุฌู ฺฉูุฏ ฺูู ุตุฑู ูุนู ุฏุฑ ุฒุจุงู ููุตุฏ ุจู ูุงุนู ูุงุจุณุชู ุงุณุช.

---

##  ูุนูุงุฑ ุงููู ุชุฑูุณููุฑูุฑ

ุฏุฑ ฺฉุงุฑุจุฑุฏ ุชุฑุฌูู:

- Encoder ฺฉู ุฌูููโ ูุจุฏุฃ ุฑุง ุจุฑุฑุณ ูโฺฉูุฏ.
- Decoder ููุท ูโุชูุงูุฏ ุจู ูุงฺูโูุง ูุจู ุฎูุฏุด ูฺฏุงู ฺฉูุฏ.
- Decoder ููฺูู ุงุฒ ุฎุฑูุฌโูุง Encoder ุจุฑุง ูพุดโุจู ูุงฺู ุจุนุฏ ุงุณุชูุงุฏู ูโฺฉูุฏ.
- ุงุฒ **attention mask** ุงุณุชูุงุฏู ูโุดูุฏ ุชุง ูุฏู ุจู ุขูุฏู ุง padding ุฏุณุชุฑุณ ูุฏุงุดุชู ุจุงุดุฏ.

---

##  ุชูุงูุช Architecture ู Checkpoint

- **Architecture (ูุนูุงุฑ)**: ุชุนุฑู ุณุงุฎุชุงุฑ ูุงูโูุง ูุฏู (ูุซูุงู BERT)
- **Checkpoint (ฺฺฉโูพููุช)**: ูุฒูโูุง ุขููุฒุดโุฏุฏูโ ูุฏู (ูุซูุงู bert-base-cased)
- **Model (ูุฏู)**: ุงุตุทูุงุญ ฺฉู ฺฉู ุจู ูุฑ ุฏู ุงุทูุงู ูโุดูุฏ

---

## ูุชุฌูโฺฏุฑ

ูุฏูโูุง ุชุฑูุณููุฑูุฑ ุจุง ูุนูุงุฑ ูุงฺููุงุฑุ ุงุฏฺฏุฑ ุฎูุฏูุธุงุฑุชุ ู ูุฏุฑุช ุชุทุจู ุจุงูุงุ ุณุชูู ููุฑุงุช ุจุณุงุฑ ุงุฒ ฺฉุงุฑุจุฑุฏูุง NLP ูุฏุฑู ูุณุชูุฏ.  
ุฏุฑ ุงุฏุงููโ ุฏูุฑูุ ูุฑ ฺฉ ุงุฒ ุงู ุงุฌุฒุง ุฑุง ุจูโุตูุฑุช ุนููโุชุฑ ุจุฑุฑุณ ุฎูุงูู ฺฉุฑุฏ.

