{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mojtaba-Choopani/huggingface-llm-course-fa-notebooks/blob/main/chapter1-transformer-models/section1-what-can-transformers-do.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 dir=\"rtl\" style=\"text-align: right; color: #2c3e50; font-family: Tahoma;\">\n",
        "مدل‌های ترنسفورمر، چه قابلیت‌هایی دارند؟\n",
        "</h1>\n"
      ],
      "metadata": {
        "id": "XI9KrkgHQWiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "در این بخش با توانایی‌های مدل‌های ترنسفورمر آشنا می‌شویم و از اولین ابزار مهم کتابخانه  Transformers یعنی تابع `pipeline()` استفاده می‌کنیم.\n",
        "\n",
        "کتابخانه Transformers امکاناتی برای استفاده و ساخت مدل‌های زبانی از پیش‌آموزش‌دیده را فراهم می‌کند. «هاب مدل» میلیون‌ها مدل آماده دارد که می‌توان آن‌ها را دانلود یا مدل‌های شخصی خود را در آن بارگذاری کرد.\n",
        "\n",
        "- استفاده از pipeline:\n",
        "تابع `pipeline()` ساده‌ترین و مهم‌ترین ابزار در کتابخانه Transformers است. این تابع مدل را با مراحل پیش‌پردازش و پس‌پردازش لازم ترکیب می‌کند تا بتوانیم مستقیم متنی را وارد کنیم و یک پاسخ قابل‌فهم دریافت کنیم.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "aVbwrC1ZsQxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "\n",
        "دستور زیر سه ابزار کلیدی از Hugging Face را نصب می‌کند که برای پروژه‌های پردازش زبان طبیعی (NLP) بسیار کاربردی هستند:\n",
        "\n",
        "- **`datasets`**: برای دسترسی آسان به دیتاست‌های متنوع و آماده‌ی NLP  \n",
        "- **`evaluate`**: برای محاسبه معیارهای ارزیابی مدل‌ها مانند accuracy و F1-score  \n",
        "- **`transformers[sentencepiece]`**: برای استفاده از مدل‌های زبانی پیشرفته مانند BERT و GPT به همراه پشتیبانی از توکن‌سازی پیشرفته (SentencePiece)\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "vDgdJ2hhrtY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNyhCA3dKRW4"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "اسکریپت  زیر یک پایپ‌لاین آماده‌ی تحلیل احساس (Sentiment Analysis) از کتابخانه  Transformers می‌سازد و آن را در متغیری به نام `classifier` ذخیره می‌کند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "wh2tyvXmwHRp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi9QUTHHKRW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804659d7-d0c0-49a6-9039-b4478b59af0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
        ")\n",
        "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGW1WlGiKRW8",
        "outputId": "ce427bfc-152b-4524-a6dc-1872be8a1a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "classifier(\n",
        "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "**تحلیل احساس با pipeline**\n",
        "\n",
        "به‌صورت پیش‌فرض، تابع `pipeline()` یک مدل از پیش‌آموزش‌دیده‌ی مخصوص تحلیل احساسات انگلیسی را بارگذاری می‌کند.  \n",
        "مدل فقط بار اول دانلود می‌شود و دفعات بعد از حافظه کش استفاده می‌گردد.\n",
        "\n",
        "-  مراحل انجام تحلیل احساسات:\n",
        "1. متن ورودی پیش‌پردازش می‌شود تا مدل بتواند آن را درک کند.\n",
        "2. ورودی پیش‌پردازش‌شده به مدل داده می‌شود.\n",
        "3. خروجی مدل پس‌پردازش می‌شود تا برای کاربر قابل‌فهم شود.\n",
        "\n",
        "---\n",
        "\n",
        "-  انواع pipeline‌ های پشتیبانی‌شده\n",
        "\n",
        "-  متنی (Text):\n",
        "- `text-generation`: تولید متن از روی یک پیام\n",
        "- `text-classification`: دسته‌بندی متن\n",
        "- `summarization`: خلاصه‌سازی متن\n",
        "- `translation`: ترجمه زبان‌ها\n",
        "- `zero-shot-classification`: دسته‌بندی بدون نیاز به آموزش قبلی\n",
        "- `feature-extraction`: استخراج بردارهای معنایی از متن\n",
        "\n",
        "-  تصویری (Image):\n",
        "- `image-to-text`: توصیف تصویر با متن\n",
        "- `image-classification`: تشخیص اشیاء در تصویر\n",
        "- `object-detection`: شناسایی موقعیت اشیاء در تصویر\n",
        "\n",
        "-  صوتی (Audio):\n",
        "- `automatic-speech-recognition`: تبدیل گفتار به متن\n",
        "- `audio-classification`: دسته‌بندی صوت\n",
        "- `text-to-speech`: تبدیل متن به گفتار\n",
        "\n",
        "-  چندحالتی (Multimodal):\n",
        "- `image-text-to-text`: پاسخ به تصویر با توجه به یک متن ورودی\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "U1tlXXrY3Vbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "  **دسته‌بندی بدون آموزش (Zero-shot Classification)**\n",
        "\n",
        "در این روش، متنی را دسته‌بندی می‌کنیم که برچسب‌گذاری (labeling) نشده است. این یک چالش رایج در پروژه‌های واقعی است، چون برچسب‌گذاری دستی بسیار زمان‌بر بوده و به تخصص نیاز دارد.\n",
        "\n",
        "پایپ‌لاین `zero-shot-classification` این مشکل را حل می‌کند:  \n",
        "با این روش می‌توانیم **لیست برچسب‌ها (labels)** را خودمان مشخص کنیم، بدون نیاز به برچسب‌های از پیش تعیین‌شده مدل.\n",
        "\n",
        "مثلاً مدل فقط برای «مثبت» و «منفی» آموزش دیده، اما با zero-shot می‌توان از آن خواست که جمله‌ای را بین برچسب‌های دلخواه مثل «ورزشی»، «علمی» یا «احساسی» دسته‌بندی کند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "HAwzFkXJ5Kyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "در پایپ‌لاین `zero-shot-classification` اگر نام مدل را مشخص نکنید، به‌صورت پیش‌فرض از مدل `facebook/bart-large-mnli` استفاده می‌شود که برای دسته‌بندی بدون برچسب بسیار مناسب است.\n",
        "\n",
        "برای کدنویسی مطمئن‌تر می‌توانید مدل را به‌صورت صریح تعیین کنید:\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "vYi9hMDLFfFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PbLXhN5KRW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d29673-8c1b-448f-d731-2b35d7724d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'This is a course about the Transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.8445994257926941, 0.11197380721569061, 0.04342673346400261]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\"\n",
        ")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\">  تولید متن (Text Generation)\n",
        "\n",
        "در این بخش با استفاده از پایپ‌لاین `text-generation` مدلی را به کار می‌گیریم که بتواند ادامه‌ی یک متن را به‌صورت خودکار تولید کند.\n",
        "\n",
        "شما یک «پرامپت» (متن شروع) وارد می‌کنید و مدل ادامه‌ی منطقی آن را تولید می‌کند؛ مشابه قابلیت پیش‌بینی متن در گوشی‌های هوشمند.\n",
        "\n",
        "تولید متن همیشه شامل مقداری تصادفی‌بودن است، بنابراین طبیعی است که در هر بار اجرا نتایج کمی متفاوت باشند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "f4ebt_37HeHf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWbzbhLSKRW_",
        "outputId": "61447107-815c-4ce6-968c-5fc47378882f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to understand and use '\n",
              "                    'data flow and data interchange when handling user data. We '\n",
              "                    'will be working with one or more of the most commonly used '\n",
              "                    'data flows — data flows of various types, as seen by the '\n",
              "                    'HTTP'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this course, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<b style=\"font-size: 18px;\">\n",
        "می‌توانید با استفاده از آرگومان `num_return_sequences` مشخص کنید که چند خروجی متفاوت تولید شود،  \n",
        "و با آرگومان `max_length` طول نهایی متن تولیدشده را کنترل کنید.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "oSZz6M9JaeJi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCEqgT8fKRXA",
        "outputId": "e5029a0b-abef-40b8-f97e-ad7f94231430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, we will teach you how to manipulate the world and '\n",
              "                    'move your mental and physical capabilities to your advantage.'},\n",
              " {'generated_text': 'In this course, we will teach you how to become an expert and '\n",
              "                    'practice realtime, and with a hands on experience on both real '\n",
              "                    'time and real'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"In this course, we will teach you how to\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<b style=\"font-size: 18px;\">\n",
        "  استفاده از مدل دلخواه در پایپ‌لاین\n",
        "\n",
        "در مثال‌های قبلی، از مدل پیش‌فرض برای هر وظیفه استفاده شد. اما شما می‌توانید از بین مدل‌های موجود در Model Hub،  \n",
        "مدل خاصی را برای وظیفه‌ای مثل تولید متن انتخاب کنید.\n",
        "\n",
        "برای این کار:\n",
        "- وارد [Model Hub](https://huggingface.co/models) شوید.\n",
        "- از ستون سمت چپ، برچسب مرتبط با تسک موردنظر (مثلاً `text-generation`) را انتخاب کنید.\n",
        "- با انتخاب برچسب زبان‌ها، می‌توانید مدل‌هایی را بیابید که برای زبان‌های دیگر (مثلاً فارسی یا عربی) آموزش دیده‌اند.\n",
        "- حتی مدل‌های چندزبانه (Multilingual) نیز در دسترس‌اند.\n",
        "\n",
        "پس از انتخاب یک مدل، صفحه‌ای نمایش داده می‌شود که در آن یک **ویجت آنلاین** وجود دارد؛  \n",
        "با این ابزار می‌توانید **قبل از دانلود، مدل را مستقیماً در مرورگر تست کنید**.\n",
        "\n",
        "---\n",
        "\n",
        "  Inference Providers\n",
        "\n",
        "ویجت تست آنلاین مدل‌ها توسط «Inference Providers» اجرا می‌شود.  \n",
        "این ابزار علاوه‌بر نسخه رایگان، به‌صورت یک محصول پولی نیز ارائه می‌شود  \n",
        "</div>\n"
      ],
      "metadata": {
        "id": "b5kFLR4_c1-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "<b style=\"font-size: 18px;\">\n",
        " پایپ‌لاین پرکردن جای خالی (fill-mask)\n",
        "\n",
        "پایپ‌لاین `fill-mask` برای **تکمیل جای خالی در متن** طراحی شده است.  \n",
        "در این وظیفه، بخشی از متن با توکن `[MASK]` (یا مشابه آن) مخفی می‌شود و مدل تلاش می‌کند مناسب‌ترین واژه را برای جای خالی پیش‌بینی کند.\n",
        "\n",
        "این یکی از کاربردهای مهم مدل‌های زبانی مانند BERT است که بر اساس زمینه جمله، کلمات گم‌شده را بازسازی می‌کنند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "9qDomn7CfVaQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mTXX0p1KRXC",
        "outputId": "665cdb3b-de5d-4089-9f06-a7fe56ab0dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'sequence': 'This course will teach you all about mathematical models.',\n",
              "  'score': 0.19619831442832947,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical'},\n",
              " {'sequence': 'This course will teach you all about computational models.',\n",
              "  'score': 0.04052725434303284,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> پایپ‌لاین پرکردن جای خالی (fill-mask)</b>\n",
        "\n",
        "پایپ‌لاین <code>fill-mask</code> برای <b>تکمیل جای خالی در متن</b> طراحی شده است.  \n",
        "در این وظیفه، بخشی از متن با توکن <code>[MASK]</code> (یا مشابه آن) مخفی می‌شود  \n",
        "و مدل تلاش می‌کند مناسب‌ترین واژه را برای جای خالی پیش‌بینی کند.\n",
        "آرگومان <code>top_k</code> مشخص می‌کند که چند گزینه از بهترین حدس‌های مدل برای جای خالی نمایش داده شود.\n",
        "\n",
        "این یکی از کاربردهای مهم مدل‌های زبانی مانند <code>BERT</code> است که بر اساس زمینه جمله، کلمات گم‌شده را بازسازی می‌کنند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "AulJLYINQH5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> شناسایی نام‌ موجود (Named Entity Recognition - NER)</b>\n",
        "\n",
        "شناسایی نام‌ موجود (NER) وظیفه‌ای است که در آن مدل باید تشخیص دهد  \n",
        "کدام بخش‌های متن ورودی مربوط به موجودیت‌هایی مانند **افراد، مکان‌ها، یا سازمان‌ها** هستند.\n",
        "\n",
        "این پایپ‌لاین به مدل کمک می‌کند تا موجودیت‌های کلیدی را در متن استخراج کرده و برچسب‌گذاری کند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "pPdAn2KzVBKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYLQkFhaKRXD",
        "outputId": "d6471245-44b5-4254-bfa3-f7e289835605"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, \n",
              " {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, \n",
              " {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}\n",
              "]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "برای اینکه مدل بخش‌هایی از جمله که به یک موجودیت تعلق دارند را با هم گروه‌بندی کند،  \n",
        "می‌توانیم هنگام ساخت پایپ‌لاین گزینه‌ی <code>grouped_entities=True</code> را فعال کنیم.\n",
        "\n",
        "برای مثال، اگر نام یک سازمان مانند <b>Hugging Face</b> شامل چند واژه باشد،  \n",
        "مدل آن را به‌درستی به عنوان یک موجودیت یکپارچه شناسایی می‌کند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "JZvrXbYAaAbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> پاسخ به پرسش (Question Answering)</b>\n",
        "\n",
        "پایپ‌لاین <code>question-answering</code> برای پاسخ دادن به پرسش‌ها از روی یک متن مشخص (context) طراحی شده است.  \n",
        "در این روش، شما یک **پرسش** و یک **متن زمینه** وارد می‌کنید،  \n",
        "و مدل تلاش می‌کند پاسخ را از داخل همان متن پیدا کرده و ارائه دهد.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "zdsCWImiaP5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYQSpIiFKRXD",
        "outputId": "ee7b53c5-7c93-46fc-eda3-642be1c5f3ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "question_answerer(\n",
        "    question=\"Where do I work?\",\n",
        "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "توجه داشته باشید که این پایپ‌لاین پاسخ را <b>از داخل متن داده‌شده استخراج می‌کند</b>  \n",
        "و <b>پاسخ جدید تولید نمی‌کند</b>؛ یعنی فقط اطلاعات موجود در متن زمینه را بازیابی می‌کند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "6e0D9nhodr8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> خلاصه‌سازی (Summarization)</b>\n",
        "\n",
        "خلاصه‌سازی وظیفه‌ای است که در آن، متن ورودی به نسخه‌ای کوتاه‌تر تبدیل می‌شود  \n",
        "در حالی که تمام یا بیشتر جنبه‌های مهم موجود در متن حفظ می‌گردند.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "dQUBTgWOfdAz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn7RkYZ3KRXD",
        "outputId": "a2813d41-994e-47de-edec-5ef359c3a772"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': ' America has changed dramatically during recent years . The '\n",
              "                  'number of engineering graduates in the U.S. has declined in '\n",
              "                  'traditional engineering disciplines such as mechanical, civil '\n",
              "                  ', electrical, chemical, and aeronautical engineering . Rapidly '\n",
              "                  'developing economies such as China and India, as well as other '\n",
              "                  'industrial countries in Europe and Asia, continue to encourage '\n",
              "                  'and advance engineering .'}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of\n",
        "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
        "    the premier American universities engineering curricula now concentrate on\n",
        "    and encourage largely the study of engineering science. As a result, there\n",
        "    are declining offerings in engineering subjects dealing with infrastructure,\n",
        "    the environment, and related issues, and greater concentration on high\n",
        "    technology subjects, largely supporting increasingly complex scientific\n",
        "    developments. While the latter is important, it should not be at the expense\n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other\n",
        "    industrial countries in Europe and Asia, continue to encourage and advance\n",
        "    the teaching of engineering. Both China and India, respectively, graduate\n",
        "    six and eight times as many traditional engineers as does the United States.\n",
        "    Other industrial countries at minimum maintain their output, while America\n",
        "    suffers an increasingly serious decline in the number of engineering graduates\n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "همانند تولید متن، در خلاصه‌سازی نیز می‌توانید با استفاده از آرگومان‌های <code>max_length</code> و <code>min_length</code>  \n",
        "طول حداکثر یا حداقل خلاصه‌ی خروجی را مشخص کنید.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "4KA5E4X5hjT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> ترجمه متن (Translation)</b>\n",
        "\n",
        "برای ترجمه می‌توانید از مدل پیش‌فرض استفاده کنید، به‌شرطی که جفت‌زبان موردنظر (مثل <code>opus-mt-en-fa</code>)  \n",
        "را در نام تسک مشخص کنید.  \n",
        "\n",
        "اما راحت‌ترین روش این است که از Model Hub مدلی مناسب با زبان‌های دلخواه خود را انتخاب کنید.\n",
        "\n",
        "در این بخش، ترجمه از زبان فرانسه به انگلیسی را امتحان خواهیم کرد.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "Wq1jjRQsh153"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk8ATrJSKRXE",
        "outputId": "648113c6-8568-48ed-b618-1aa3f2793052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This course is produced by Hugging Face.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "result = translator(\"Ce cours est produit par Hugging Face.\")\n",
        "print(result[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> پایپ‌لاین‌های تصویر و صوت (Image and Audio Pipelines)</b>\n",
        "\n",
        "فراتر از متن، مدل‌های ترنسفورمر می‌توانند با <b>تصاویر</b> و <b>صداها</b> نیز کار کنند.  \n",
        "در ادامه چند نمونه از این کاربردها آورده شده است:\n",
        "\n",
        "- <b>Image classification:</b> دسته‌بندی تصویر\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "VTjMblqRmq3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "image_classifier = pipeline(\n",
        "    task=\"image-classification\", model=\"google/vit-base-patch16-224\"\n",
        ")\n",
        "result = image_classifier(\n",
        "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1cXdczbumSH",
        "outputId": "b4b50ba1-06a2-48c0-dd7a-84880a9c591d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'lynx, catamount', 'score': 0.43349990248680115}, {'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 'score': 0.03479622304439545}, {'label': 'snow leopard, ounce, Panthera uncia', 'score': 0.032401926815509796}, {'label': 'Egyptian cat', 'score': 0.023944783955812454}, {'label': 'tiger cat', 'score': 0.02288925088942051}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "- <b>Automatic Speech Recognition:</b> تشخیص خودکار گفتار\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "BV74wUl4vrMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "transcriber = pipeline(\n",
        "    task=\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\"\n",
        ")\n",
        "result = transcriber(\n",
        "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "sXu92qTJ8mj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "<b style=\"font-size: 18px;\"> ترکیب داده از منابع مختلف</b>\n",
        "\n",
        "یکی از کاربردهای قدرتمند مدل‌های ترنسفورمر، توانایی آن‌ها در ترکیب و پردازش داده از منابع گوناگون است.  \n",
        "این قابلیت به‌ویژه زمانی مفید است که بخواهید:\n",
        "\n",
        "- در پایگاه‌داده‌ها یا مخازن مختلف جست‌وجو انجام دهید  \n",
        "- اطلاعات را از فرمت‌های متفاوت (متن، تصویر، صوت) یکپارچه کنید  \n",
        "- نمایی هماهنگ از اطلاعات مرتبط ارائه دهید  \n",
        "\n",
        "برای مثال می‌توانید سیستمی بسازید که:\n",
        "\n",
        "- در میان پایگاه‌داده‌هایی با حالت‌های مختلف مانند متن و تصویر جست‌وجو کند  \n",
        "- نتایج منابع مختلف را در یک پاسخ منسجم ترکیب کند (مثلاً از فایل صوتی و توضیح متنی)  \n",
        "- مرتبط‌ترین اطلاعات را از یک پایگاه داده شامل اسناد و فراداده‌ها استخراج کند  \n",
        "\n",
        "---\n",
        "\n",
        "<b> جمع‌بندی</b>\n",
        "\n",
        "پایپ‌لاین‌هایی که در این فصل معرفی شدند، بیشتر برای اهداف نمایشی طراحی شده‌اند.  \n",
        "این پایپ‌لاین‌ها برای وظایف خاصی برنامه‌ریزی شده‌اند و نمی‌توانند تغییرات گسترده‌ای را اجرا کنند.\n",
        "\n",
        "در فصل بعدی، با ساختار درونی تابع <code>pipeline()</code> و روش‌های سفارشی‌سازی آن آشنا خواهید شد.\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "EzqLaTUt1CT4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tw7mSyoL1NAY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Transformers, what can they do?",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}